{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Sentiment_Analysis_DKK_Semarang_(LSTM)",
      "provenance": [],
      "collapsed_sections": [
        "KE08uHcp3PCp",
        "MAUdm8NMXrXN",
        "fhnLEGNLuEbP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfifau/sentiment-dkk-semarang/blob/main/notebooks/Sentiment_Analysis_DKK_Semarang_(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE08uHcp3PCp"
      },
      "source": [
        "### **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hneUfcUg3SRQ"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string, re, requests, csv\n",
        "from google.colab import drive\n",
        "from wordcloud import WordCloud\n",
        "from gensim.corpora import WikiCorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghWtEwwt9zAn",
        "outputId": "6c6484ae-2a2a-402f-ba1f-1bc685faa4e8"
      },
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Z_mhXhqNK2",
        "outputId": "c5832023-5229-45d0-d65f-a357082e78ff"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.0.tar.gz (168 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 168 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.0-py3-none-any.whl size=168256 sha256=de8a1723aa0f0bf3aa2ab24eae598a06c034266c200bc89ff1444b334f3aff10\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/d7/74/c720aaf345a042b0c2d74361873258c5e8649b7f11b2ccce49\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAUdm8NMXrXN"
      },
      "source": [
        "### **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYJ4ZmLXtXIv",
        "outputId": "820e40eb-769a-473a-ad90-66fa299c2adc"
      },
      "source": [
        "train_data = pd.read_csv('/content/train.csv')\n",
        "train_data = train_data[['text', 'label']]\n",
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7967, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSmd0ufRtrcf",
        "outputId": "e1f2100e-e9b4-4a99-80f8-5ecc5a63c607"
      },
      "source": [
        "train_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     2926\n",
              "negative    2775\n",
              "positive    2266\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy0JV6eytyDP",
        "outputId": "ea2b54f9-1ec4-43b4-b275-6341c4b27cab"
      },
      "source": [
        "test_data = pd.read_csv('/content/test.csv')\n",
        "test_data = test_data[['text', 'label']]\n",
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1992, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv32SZKjt8yW",
        "outputId": "65bcda10-126d-41fa-ee81-312586461579"
      },
      "source": [
        "test_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     732\n",
              "negative    694\n",
              "positive    566\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RASVz11HtL5w"
      },
      "source": [
        "### **All Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F2xvjdUpHLy"
      },
      "source": [
        "# comments = data['text']\n",
        "comments_train = train_data['text']\n",
        "comments_test = test_data['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ7eJcf2saVm"
      },
      "source": [
        "### 1. Replace Username\n",
        "def replace_username(data):\n",
        "  pattern = \"(?:@)([A-Za-z0-9_](?:(?:[A-Za-z0-9_]|(?:\\.(?!\\.))){0,28}(?:[A-Za-z0-9_]))?)\"\n",
        "  data = re.sub(pattern, \"@username\", data)\n",
        "  \n",
        "  return data\n",
        "\n",
        "### 2. Cleansing Data\n",
        "def cleansing(data):\n",
        "    # lowercasing\n",
        "    data = data.lower()\n",
        "\n",
        "    # remove punctuation\n",
        "    punct = string.punctuation\n",
        "    translator = str.maketrans(punct, ' '*len(punct))\n",
        "    data = data.translate(translator)\n",
        "\n",
        "    # remove ASCII dan unicode\n",
        "    data = data.encode('ascii', 'ignore').decode('utf-8')\n",
        "    data = re.sub(r'[^\\x00-\\x7f]',r'', data)\n",
        "    \n",
        "    # remove newline\n",
        "    data = data.replace('\\n', ' ')\n",
        "\n",
        "    # remove digit\n",
        "    pattern = r'[0-9]'\n",
        "    data = re.sub(pattern, '', data)\n",
        "\n",
        "    # remove extra space\n",
        "    data = ' '.join(data.split())\n",
        "    \n",
        "    return data\n",
        "\n",
        "# ### 3. Remove Emoji  \n",
        "import sys\n",
        "def remove_emoji(data):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r' ', data)\n",
        "\n",
        "### 3. Convert Emoji\n",
        "import emoji\n",
        "import functools\n",
        "import operator\n",
        "import re\n",
        "\n",
        "df_emoji = pd.read_csv('emoji_to_text.csv')\n",
        "UNICODE_EMO = {row['emoji']:row['makna'] for idx,row in df_emoji.iterrows()}\n",
        "def convert_emojis(text):\n",
        "    # split emojis\n",
        "    em_split_emoji = emoji.get_emoji_regexp().split(text)\n",
        "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
        "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
        "    text = ' '.join(em_split)\n",
        "\n",
        "    # convert emojis\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
        "    return text.lower()\n",
        "  \n",
        "### 4. Normalize Kata Alay\n",
        "# CONSTRUCT KAMUS ALAY\n",
        "text_path1 = 'https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/kbba.txt'\n",
        "text_path2 = 'https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv'\n",
        "kamus_alay1 = pd.read_csv(text_path1, delimiter=\"\\t\", header=None, names=['slang', 'formal'])\n",
        "kamus_alay2 = pd.read_csv(text_path2)\n",
        "kamus_alay = pd.concat([kamus_alay1, kamus_alay2[['slang', 'formal']]]).reset_index(drop=True)\n",
        "\n",
        "dict_alay = dict()\n",
        "for index, row in kamus_alay.iterrows():\n",
        "    dict_alay[row['slang']] = row['formal']\n",
        "\n",
        "def normalize_text(data):\n",
        "  word_tokens = word_tokenize(data)\n",
        "  result = [dict_alay.get(w,w) for w in word_tokens]\n",
        "  return ' '.join(result)\n",
        "\n",
        "\n",
        "### 5. Remove Stopwords\n",
        "# CONSTRUCT STOPWORDS\n",
        "rama_stopword = \"https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/stopword.txt\"\n",
        "yutomo_stopword = \"https://raw.githubusercontent.com/yasirutomo/python-sentianalysis-id/master/data/feature_list/stopwordsID.txt\"\n",
        "fpmipa_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/fpmipa-stopwords.txt\"\n",
        "sastrawi_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/sastrawi-stopwords.txt\"\n",
        "aliakbar_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/aliakbars-bilp.txt\"\n",
        "pebahasa_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/pebbie-pebahasa.txt\"\n",
        "elang_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-id.txt\"\n",
        "nltk_stopword = stopwords.words('indonesian')\n",
        "\n",
        "path_stopwords = [rama_stopword, yutomo_stopword, fpmipa_stopword, sastrawi_stopword, \n",
        "                  aliakbar_stopword, pebahasa_stopword, elang_stopword]\n",
        "\n",
        "# CUSTOM STOPWORDS\n",
        "other = '''\n",
        "admin mimin min minkes kalo nya username\n",
        "'''\n",
        "\n",
        "# gabungkan stopwords\n",
        "stopwords_l = nltk_stopword\n",
        "for path in path_stopwords:\n",
        "    response = requests.get(path)\n",
        "    stopwords_l += response.text.split('\\n')\n",
        "\n",
        "st_words = set(stopwords_l)\n",
        "other_stopword = set(other.split())\n",
        "\n",
        "stop_words = st_words | other_stopword\n",
        "\n",
        "def remove_stopword(text, stop_words=stop_words):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return ' '.join(filtered_sentence)\n",
        "\n",
        "def preprocessing(data):\n",
        "  data = replace_username(data)\n",
        "  data = cleansing(data)\n",
        "  # data = remove_emoji(data)\n",
        "  data = convert_emojis(data)\n",
        "  data = normalize_text(data)\n",
        "  data = remove_stopword(data)\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6xAdZXav1jA"
      },
      "source": [
        "comments_train = comments_train.apply(lambda x: preprocessing(x))\n",
        "comments_test = comments_test.apply(lambda x: preprocessing(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCqy3X-Ev-tS",
        "outputId": "221e6220-cd8f-4ea4-be98-ec40c4455fca"
      },
      "source": [
        "comments_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                     \n",
              "1                                     turun maju canik\n",
              "2        prosentase kematian covid warga kota semarang\n",
              "3    rapid test test swab pcr kawan-kawan dinkes se...\n",
              "4                                      area pedurungan\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNJpXWuWxEkm",
        "outputId": "13efce57-9caa-447e-fd5d-f2f08f50cf94"
      },
      "source": [
        "comments_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                             vaksin massal cek vaksin\n",
              "1             kak coba coba ulang terima kasih infonya\n",
              "2                           tugu graha padma isoman cc\n",
              "3    terimakasih infonya berharap update informasi ...\n",
              "4                                            ayo turun\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJDohUS69zhu"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgBMo3tEzknb",
        "outputId": "e8a835af-de6e-458b-85c7-30c69b46a2ea"
      },
      "source": [
        "y_train =  pd.get_dummies(train_data['label']).values\n",
        "y_test =  pd.get_dummies(test_data['label']).values\n",
        "\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7967, 3), (1992, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrstO7NIwPGX",
        "outputId": "7cc036b0-0c5c-4af5-c620-05d074a75a4b"
      },
      "source": [
        "y_train[1], y_train[0], y_train[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 0], dtype=uint8),\n",
              " array([1, 0, 0], dtype=uint8),\n",
              " array([0, 0, 1], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhnLEGNLuEbP"
      },
      "source": [
        "## **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWqLJ8IE91An",
        "outputId": "21e44a62-eb87-457e-e259-06dd812e16c9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 5000, ngram_range = (1, 3),\n",
        "                              sublinear_tf = True )\n",
        "\n",
        "comments_train_tfidf = vectorizer.fit_transform(comments_train).toarray()\n",
        "comments_test_tfidf = vectorizer.transform(comments_test).toarray()\n",
        "\n",
        "comments_train_tfidf.shape, comments_test_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7967, 5000), (1992, 5000))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f00EArwMusMK",
        "outputId": "5dc5c55c-fe08-4cc2-eea1-cbae543d75ec"
      },
      "source": [
        "# reshape, since LSTM cells expects ndims = 3\n",
        "comments_train_tfidf = comments_train_tfidf.reshape(comments_train_tfidf.shape[0], 1, comments_train_tfidf.shape[-1])\n",
        "comments_test_tfidf = comments_test_tfidf.reshape(comments_test_tfidf.shape[0], 1, comments_test_tfidf.shape[-1])\n",
        "\n",
        "comments_train_tfidf.shape, comments_test_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7967, 1, 5000), (1992, 1, 5000))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diktXwF5vqWe"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udS_kdtHMZ2x"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "from keras_tuner.tuners import RandomSearch \n",
        "from keras_tuner.tuners import Hyperband\n",
        "\n",
        "# Build out our simple LSTM\n",
        "# # Model saving callback\n",
        "# mc = ModelCheckpoint('keras_model', \n",
        "#                                  monitor='val_loss', \n",
        "#                                  verbose=1, \n",
        "#                                  save_best_only=True, \n",
        "#                                  mode='auto')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(lstm_out, dropout=dropout, input_shape = comments_train_tfidf.shape[1:])) # recurrent dropout?\n",
        "# model.add(Dense(3,activation='softmax'))\n",
        "# opt = Adam(learning_rate=lr)\n",
        "# model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "# print(model.summary())\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Choice('lstm_out',values=[32, 48, 64]), input_shape=comments_train_tfidf.shape[1:]))\n",
        "    model.add(Dropout(hp.Choice('dropout',values=[0.2, 0.5, 0.8])))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    lr = hp.Choice('learning_rate',values=[0.1, 0.01, 0.001, 0.0001])\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlkaKpTQyja6",
        "outputId": "fff8cf7b-5aa3-4aa5-f99b-fc228a2b42b7"
      },
      "source": [
        "tuner= RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=36,\n",
        "        executions_per_trial=1,\n",
        "        directory='randomsearch-tfidf-emoji-05',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 32)                644224    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 644,323\n",
            "Trainable params: 644,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6TjsBr8ysA9",
        "outputId": "0423f271-a128-4b7f-95a8-5fd4093757de"
      },
      "source": [
        "tuner.search(\n",
        "      x=comments_train_tfidf,\n",
        "      y=y_train,\n",
        "      epochs=100,\n",
        "      batch_size=32,\n",
        "      validation_split=0.2,\n",
        "      callbacks=[es]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 29 Complete [00h 00m 49s]\n",
            "val_accuracy: 0.7095357775688171\n",
            "\n",
            "Best val_accuracy So Far: 0.7126725316047668\n",
            "Total elapsed time: 00h 33m 28s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHdOiHXY5afB",
        "outputId": "4cf6ea16-b803-4f0c-b663-75a79538fded"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in randomsearch-tfidf-emoji-05/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.8\n",
            "learning_rate: 0.001\n",
            "Score: 0.7126725316047668\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.5\n",
            "learning_rate: 0.01\n",
            "Score: 0.7107904553413391\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.5\n",
            "learning_rate: 0.001\n",
            "Score: 0.7107904553413391\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.2\n",
            "learning_rate: 0.001\n",
            "Score: 0.7101631164550781\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.8\n",
            "learning_rate: 0.01\n",
            "Score: 0.7101631164550781\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.8\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7101631164550781\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.5\n",
            "learning_rate: 0.001\n",
            "Score: 0.7095357775688171\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.5\n",
            "learning_rate: 0.001\n",
            "Score: 0.7095357775688171\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.8\n",
            "learning_rate: 0.001\n",
            "Score: 0.7089083790779114\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.5\n",
            "learning_rate: 0.0001\n",
            "Score: 0.7082810401916504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teQJlrOG9M59",
        "outputId": "e5f59e37-b291-48ac-9920-8920dc67a717"
      },
      "source": [
        "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "bestHP.get(\"lstm_out\"), bestHP.get(\"dropout\"), bestHP.get(\"learning_rate\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 0.8, 0.001)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfBe4hKG5hgM",
        "outputId": "6fa373b1-31ec-4a62-947b-20600e24efc8"
      },
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                1296640   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 1,296,835\n",
            "Trainable params: 1,296,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwMGklaQ5mP-",
        "outputId": "d71ba93f-a4b8-4d38-b874-b0475bf30140"
      },
      "source": [
        "loss, accuracy = best_model.evaluate(comments_test_tfidf, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 5ms/step - loss: 0.6535 - accuracy: 0.7209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKKAwOzezBeW"
      },
      "source": [
        "# **Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBx9vipt_yrE",
        "outputId": "49ad4e83-bf9e-40e0-b622-dae1ed01873e"
      },
      "source": [
        "# dowload pre-trained word2vec fasttext indonesia\n",
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
        "# unzip\n",
        "! gunzip cc.id.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 01:35:17--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4507049071 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.id.300.bin.gz’\n",
            "\n",
            "cc.id.300.bin.gz     45%[========>           ]   1.91G  28.2MB/s    in 72s     \n",
            "\n",
            "2021-10-09 01:36:29 (27.1 MB/s) - Read error at byte 2049453432/4507049071 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2021-10-09 01:36:30--  (try: 2)  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 4507049071 (4.2G), 2457595639 (2.3G) remaining [application/octet-stream]\n",
            "Saving to: ‘cc.id.300.bin.gz’\n",
            "\n",
            "cc.id.300.bin.gz    100%[+++++++++==========>]   4.20G  28.5MB/s    in 83s     \n",
            "\n",
            "2021-10-09 01:37:54 (28.1 MB/s) - ‘cc.id.300.bin.gz’ saved [4507049071/4507049071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TumUz1H_0BR"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "# load pre-trained word2vec fasttext\n",
        "word2vec = FastText.load_fasttext_format('cc.id.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAOVLz4xA1p5"
      },
      "source": [
        "# tokenize text\n",
        "def tokenize(sentence):\n",
        "    return word_tokenize(sentence)\n",
        "\n",
        "train_text = comments_train.apply(lambda x: tokenize(x))\n",
        "test_text = comments_test.apply(lambda x: tokenize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89NvRJwSDsx_"
      },
      "source": [
        "# vectorize\n",
        "VOCABULARY = word2vec.wv.vocab\n",
        "def vectorize(tokens):\n",
        "    word_vec = []\n",
        "    for w in tokens:\n",
        "        if w in VOCABULARY:\n",
        "            # get word vector from pre-trained word2vec fasttext\n",
        "            word_vec.append(word2vec[w])\n",
        "    return word_vec\n",
        "\n",
        "def avg_vectorize(tokens):\n",
        "    sum_vec = np.zeros(300)\n",
        "    word_count = 0\n",
        "\n",
        "    for w in tokens:\n",
        "        if w in VOCABULARY:\n",
        "            # word vector from pre-trained word2vec fasttext and add vector\n",
        "            sum_vec += word2vec[w]\n",
        "            word_count += 1\n",
        "    return sum_vec if word_count==0 else sum_vec/word_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36hejfHeDvEm",
        "outputId": "0bc0c4d4-d9df-449e-a542-feeb098126a6"
      },
      "source": [
        "# check maximum token and count\n",
        "max_size_token = 0\n",
        "count = 0\n",
        "max_len_choosen = 50\n",
        "\n",
        "for tok in train_text:\n",
        "    # find max token\n",
        "    if len(tok) > max_size_token: max_size_token = len(tok)\n",
        "    # count\n",
        "    if len(tok) > max_len_choosen: count += 1\n",
        "\n",
        "print(f'Maximum length token: {max_size_token}')\n",
        "print(f'With MAX_LEN {max_len_choosen}, there are/is {count} token/s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length token: 150\n",
            "With MAX_LEN 50, there are/is 24 token/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNujZUgPDxFR"
      },
      "source": [
        "# padding\n",
        "MAX_LEN = 50\n",
        "\n",
        "def add_padding(word_vec):\n",
        "    if len(word_vec) < MAX_LEN:\n",
        "        pad_count = MAX_LEN - len(word_vec)\n",
        "        return word_vec + [np.array([0]*300)]*pad_count\n",
        "    else:\n",
        "        return word_vec[:MAX_LEN]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLpkezGLDzA1"
      },
      "source": [
        "# feature extraction\n",
        "def extract_feature(data, ndim=3):\n",
        "    if ndim == 3:\n",
        "        features = vectorize(data)\n",
        "        features = add_padding(features)\n",
        "    elif ndim == 2:\n",
        "        features = avg_vectorize(data)\n",
        "    return np.array(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s0X8-JfFKTa",
        "outputId": "06c858dd-5acd-4c6f-9619-e00619ea9e79"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# extract feature\n",
        "comments_train_w2v = np.array([extract_feature(text, ndim=3) for text in train_text])\n",
        "comments_test_w2v = np.array([extract_feature(text, ndim=3) for text in test_text])\n",
        "\n",
        "comments_train_w2v.shape, comments_test_w2v.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7967, 50, 300), (1992, 50, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU8pdmj3gCkJ",
        "outputId": "cb818839-82d3-4fdb-cedb-37d9dfaec098"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 2.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG0mxxcwFVFq"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "from keras_tuner.tuners import RandomSearch \n",
        "from keras_tuner.tuners import Hyperband\n",
        "\n",
        "# Build out our simple LSTM\n",
        "\n",
        "# Model saving callback\n",
        "# mc = ModelCheckpoint('keras_model', \n",
        "#                                  monitor='val_loss', \n",
        "#                                  verbose=1, \n",
        "#                                  save_best_only=True, \n",
        "#                                  mode='auto')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "# model2 = Sequential()\n",
        "# model2.add(LSTM(lstm_out, dropout=dropout, input_shape = train_features.shape[1:])) # recurrent dropout?\n",
        "# model2.add(Dense(3,activation='softmax'))\n",
        "# opt = Adam(learning_rate=lr)\n",
        "# model2.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "# print(model2.summary())\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Choice('lstm_out',values=[32, 48, 64]), input_shape=comments_train_w2v.shape[1:]))\n",
        "    model.add(Dropout(hp.Choice('dropout',values=[0.2, 0.5, 0.8])))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    lr = hp.Choice('learning_rate',values=[0.1, 0.01, 0.001, 0.0001])\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjUUv5EBdjBy",
        "outputId": "1e6d506d-eec8-410b-ae8a-df16ac52158a"
      },
      "source": [
        "tuner= RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=36,\n",
        "        executions_per_trial=1,\n",
        "        directory='randomsearch_w2v-emoji-09',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 32)                42624     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 42,723\n",
            "Trainable params: 42,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC8-J6ipdpZJ",
        "outputId": "f82b69e3-9fb2-49da-8cd8-a47fbab00aed"
      },
      "source": [
        "tuner.search(\n",
        "      x=comments_train_w2v,\n",
        "      y=y_train,\n",
        "      epochs=100,\n",
        "      batch_size=32,\n",
        "      validation_split=0.2,\n",
        "      callbacks=[es]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 31 Complete [00h 04m 12s]\n",
            "val_accuracy: 0.5727729201316833\n",
            "\n",
            "Best val_accuracy So Far: 0.7120451927185059\n",
            "Total elapsed time: 01h 56m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWBU6kq0dMn7",
        "outputId": "5e834582-32c8-4028-da87-5fad98f9fed1"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in randomsearch_w2v-emoji-09/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.7120451927185059\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.5\n",
            "learning_rate: 0.01\n",
            "Score: 0.702007532119751\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.8\n",
            "learning_rate: 0.001\n",
            "Score: 0.6988707780838013\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.6976160407066345\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.6957340240478516\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 48\n",
            "dropout: 0.8\n",
            "learning_rate: 0.01\n",
            "Score: 0.6957340240478516\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.5\n",
            "learning_rate: 0.001\n",
            "Score: 0.6938519477844238\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.8\n",
            "learning_rate: 0.001\n",
            "Score: 0.6882057785987854\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 32\n",
            "dropout: 0.2\n",
            "learning_rate: 0.001\n",
            "Score: 0.6875784397125244\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_out: 64\n",
            "dropout: 0.8\n",
            "learning_rate: 0.001\n",
            "Score: 0.6869510412216187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_cxAGVZgb93",
        "outputId": "218d3e7f-38ff-407b-dbef-ae96acae508b"
      },
      "source": [
        "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "bestHP.get(\"lstm_out\"), bestHP.get(\"dropout\"), bestHP.get(\"learning_rate\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 0.2, 0.01)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UTyWrpTgiVY",
        "outputId": "7b9f7818-8a04-44a4-f30a-9fa92fca6197"
      },
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 32)                42624     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 42,723\n",
            "Trainable params: 42,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9UWMO9FgizU",
        "outputId": "1208c041-9af3-4d37-b50b-4c279b9f1df3"
      },
      "source": [
        "loss, accuracy = best_model.evaluate(comments_test_w2v, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 11ms/step - loss: 0.7185 - accuracy: 0.7028\n"
          ]
        }
      ]
    }
  ]
}